{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb12759e-b333-48ed-8245-5fb896272045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import numpy.ma as ma \n",
    "import awkward as ak\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch_geometric as tg\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "#import torch\n",
    "from torch_geometric.data import InMemoryDataset, download_url\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "#NOTE: NEW 2/20/23 \n",
    "from typing import List, Union\n",
    "\n",
    "from torch_geometric.data import Data, HeteroData\n",
    "from torch_geometric.data.datapipes import functional_transform\n",
    "from torch_geometric.transforms import BaseTransform  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d9ae419-9df6-45ca-a777-d765bb192ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyOwnDataset(17975)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "root = '/hpc/group/vossenlab/kam264/mom_pro_pi_x_cx_reczfull_20000' \n",
    "class MyOwnDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.load(self.processed_paths[0])\n",
    "        # For PyG<2.4:\n",
    "        # self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['some_file_1', 'some_file_2']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "\n",
    "    def process(self):\n",
    "        # Read data into huge `Data` list.\n",
    "        data_list = None\n",
    "\n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(data) for data in data_list]\n",
    "\n",
    "        self.save(data_list, self.processed_paths[0])\n",
    "        # For PyG<2.4:\n",
    "        # torch.save(self.collate(data_list), self.processed_paths[0])\n",
    "\n",
    "# Create PyG Dataset\n",
    "#root = '/hpc/group/vossenlab/kam264/pyg_test_rec_traj_dataset_5_28_24/' # 3_14_24 #OLD\n",
    "dataset = MyOwnDataset(\n",
    "            root,\n",
    "            transform=None, #T.Compose([T.ToUndirected(),T.KNNGraph(k=6)]),\n",
    "            pre_transform=None,\n",
    "            pre_filter=None\n",
    "        )\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceeb0c8-748a-489d-849f-11cb5a572d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590b978d-71ad-4823-b3b2-288b0941c8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device =  cuda:0\n",
      "DEBUGGING: torch.cuda.is_available() =  True\n",
      "Number of training graphs: 14380\n",
      "Number of validation graphs: 1797\n",
      "Number of test graphs: 1798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/home/kam264/.local/lib/python3.8/site-packages/torch_geometric/data/dataset.py:169: UserWarning: Found floating-point labels while calling `dataset.num_classes`. Returning the number of unique elements. Please make sure that this is expected before proceeding.\n",
      "  warnings.warn(\"Found floating-point labels while calling \"\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import GraphConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.nn.norm import GraphNorm, BatchNorm \n",
    "\n",
    "batch_size = 32 \n",
    "LR =1e-4\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GCN, self).__init__()\n",
    "#         torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)#.jittable() #NOTE: NEEDED FOR DEPLOYMENT IN CMAKE\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)#.jittable()\n",
    "        #self.block2 = nn.DataParallel(self.block2)\n",
    "        #self.conv2 = torch.nn.DataParallel(self.conv2) #this was trying the parallization thing. \n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)#.jittable()\n",
    "        #self.conv3 = torch.nn.DataParallel(self.conv3)\n",
    "        self.lin1 = Linear(hidden_channels, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, hidden_channels)\n",
    "        self.lin3 = Linear(hidden_channels, out_channels)\n",
    "        self.bn1 = torch_geometric.nn.norm.GraphNorm(hidden_channels)\n",
    "        self.bn2 = torch_geometric.nn.norm.GraphNorm(hidden_channels)\n",
    "        self.bn3 = torch_geometric.nn.norm.GraphNorm(hidden_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch): \n",
    "        # 1. Obtain node embeddings \n",
    "       # x = self.conv1(x, edge_index) #input layer\n",
    "      #  x = self.bn1(x) #normalize it\n",
    "     #   x = x.relu() #activation\n",
    "#         x = torch.nn.function.elu(x)\n",
    "#        x = self.conv2(x, edge_index)\n",
    "#        x = self.bn2(x)\n",
    "#        x = x.relu() \n",
    "#         print(\"x.relu() = \",x)\n",
    "#        x = self.conv3(x, edge_index)\n",
    "#        x = self.bn3(x)\n",
    "#         # 2. Readout layer\n",
    " #       x = global_mean_pool(x, batch) #what is this for.           # [batch_size, hidden_channels]\n",
    "  #      x = F.dropout(x, p=0.5, training=self.training) #for overfitting\n",
    "   #     x = self.lin3(x)\n",
    "        \n",
    "        x = self.conv1(x, edge_index) #input layer                             \n",
    "                                                      \n",
    "        x = self.bn1(x) #normalize it                                          \n",
    "\n",
    "        x = x.relu() #activation                                               \n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.bn2(x)\n",
    "        x = x.relu()\n",
    "#         print(\"x.relu() = \",x)                                               \n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = self.bn3(x)\n",
    "#         # 2. Readout layer                                                   \n",
    "        x = global_mean_pool(x, batch)\n",
    "        # 3. Apply a final classifier                                          \n",
    "        x = F.dropout(x, p=0.5, training=self.training) #for overfittin        \n",
    "        x = self.lin3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = GCN(dataset.num_node_features,64,2)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') \n",
    "#devicee = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu') \n",
    "print(\"Device = \",device)\n",
    "model = model.to(device)\n",
    "print(\"DEBUGGING: torch.cuda.is_available() = \",torch.cuda.is_available())\n",
    "\n",
    "from torch.utils.data import random_split #TODO: SEE IF YOU CAN USE THIS\n",
    "# torch.manual_seed(12345)\n",
    "# print('DEBUGGING: BEFORE: dataset.y.shape = ',dataset.y.shape)\n",
    "dataset = dataset.shuffle() #shuffle (randmoize placement of it) not sure if this is needed. \n",
    "#print('DEBUGGING: AFTER:  dataset.y.shape = ',dataset.y.shape)\n",
    "\n",
    "#print(len(dataset)) \n",
    "\n",
    "fracs = [0.8, 0.1, 0.1] #percent of dataset used for training testing and validatoin 80%,10%,10% #NOTE: SHOULD CHECK np.sum(fracs) == 1 and len(fracs)==3\n",
    "fracs = [torch.sum(torch.tensor(fracs[:idx])) for idx in range(1,len(fracs)+1)] #get the indexes for training ... parts to use. \n",
    "#print(fracs)\n",
    "split1, split2 = [int(len(dataset)*frac) for frac in fracs[:-1]] \n",
    "train_dataset = dataset[:split1]\n",
    "val_dataset = dataset[split1:split2]\n",
    "test_dataset = dataset[split2:] \n",
    "\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of validation graphs: {len(val_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}') \n",
    "\n",
    "from torch_geometric.loader import DataLoader \n",
    "#from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)#, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset,  batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False) \n",
    "\n",
    "model = GCN(dataset.num_node_features, dataset.num_classes, 2).to(device) #initiate the model, #2 is the number of outputs here is 2 as pion_z, proton_z \n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr= LR) #get the optimizer\n",
    "\n",
    "data_labels = train_dataset.y \n",
    "#weight_signal = counts[1]/counts[0]#DEBUGGING MULTIPLY BY 2 ...\n",
    "#print(\"weight_signal = \",weight_signal) \n",
    "# weight = torch.FloatTensor([weight_signal, 1.0]).to(device) #NOTE: That labels are [sg?,bg?] so label 0 in this case is sg and label 1 is bg.\n",
    "\n",
    "\n",
    "#losss = torch.nn.MSELoss(reduction = 'mean').to(device)\n",
    "#losss = torch.sqrt(losss)\n",
    "\n",
    "#RMSE loss. \n",
    "def RMSELoss(out,y):\n",
    "    return torch.sqrt(torch.mean((out-y)**2))\n",
    "losss = RMSELoss \n",
    "\n",
    "#custom losss\n",
    "def pion_los(out,y):\n",
    "    mse_pi = 0\n",
    "    for j in range(len(out)):\n",
    "            #x_pi = out[j][0]; x_p =out[j][1]                                                                                                                                                                                                 \n",
    "\n",
    "        mse_pi += (out[j][0]-y[j][0].item() )**2\n",
    "    return torch.sqrt(mse_pi/len(out))\n",
    "\n",
    "#losss = pion_los\n",
    "\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train() #initailize the model                                                                                                                                                                                                       \n",
    "    #for i, data in tqdm(enumerate(train_loader)): #perhaps tqdm(enumerate(train_loader)), i is index, data jsut moves through all the dtaa in trainingg                                                                                      \n",
    "    for i,data in enumerate(train_loader):\n",
    "        data = data.to(device) #switch to GPU                                                                                                                                                                                                 \n",
    "        optimizer.zero_grad() #                                                                                                                                                                                                               \n",
    "        out = model(data.x, data.edge_index, data.batch).to(device)  # Perform a single forward pass                                                                                                                                          \n",
    "        yy = []\n",
    "        for j in range(0,2*len(out),2):\n",
    "\n",
    "            yy +=[[data.y[j].item(), data.y[j+1].item()]]\n",
    "\n",
    "        yy = torch.tensor(yy).to(device)\n",
    "        loss = losss(out, yy).to(device) #compute the loss                                                                                                                                                                                    \n",
    "        loss.backward() #get the gradients.                                                                                                                                                                                                   \n",
    "        optimizer.step() #take a step.                                                                                                                                                                                                        \n",
    "\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "#from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def test(loader):\n",
    "    length = len(loader.dataset)\n",
    "    model.eval() #evaluate teh model.                                                                                                                                                                                                         \n",
    "\n",
    "    #mse_tot = []                                                                                                                                                                                                                             \n",
    "    mse_total = 0\n",
    "    mse_pi = 0\n",
    "    mse_p = 0\n",
    "    #r                                                                                                                                                                                                                                        \n",
    "    #for data in tqdm(loader):  # Iterate in batches over the training/test dataset.                                                                                                                                                          \n",
    "    for data in loader:\n",
    "        data = data.to(device) #put to GPU                                                                                                                                                                                                    \n",
    "        out = model(data.x, data.edge_index, data.batch).to(device) #evalueate                                                                                                                                                                \n",
    "        #this and the for loop is converting data.y to a tensor in the same shape as out rows and 2 columns first is y_pion second is y_proton                                                                                                \n",
    "        yy = []\n",
    "        for j in range(0,2*len(out),2):\n",
    "            yy +=[[data.y[j].item(),data.y[j+1].item()]]\n",
    "        yy = torch.tensor(yy).to(device) \n",
    "        loss = losss(out, yy).cpu() #getting teh loss function                                                                                                                                                                                \n",
    "        mse_total+=loss.item() #getting the mse (total)                                                                                                                                                                                       \n",
    "        for j in range(len(out)):\n",
    "            #x_pi = out[j][0]; x_p =out[j][1]                                                                                                                                                                                                 \n",
    "\n",
    "            mse_pi += (out[j][0].item()-yy[j][0].item() )**2\n",
    "            mse_p +=(out[j][1].item()-yy[j][1].item())**2\n",
    "\n",
    "        #)                                                                                                                                                                                                                                    \n",
    "    return mse_total/length, np.sqrt(mse_total/length), mse_pi/length, np.sqrt(mse_pi/length), mse_p/length, np.sqrt(mse_p/length)\n",
    "\n",
    "        \n",
    "def print_out():\n",
    "    model.eval() #initailize the model                                                                                                                                                                                                        \n",
    "    #for i, data in tqdm(enumerate(train_loader)): #perhaps tqdm(enumerate(train_loader)), i is index, data jsut moves through all the dtaa in trainingg                                                                                      \n",
    "    outt= []\n",
    "    for i,data in enumerate(train_loader):\n",
    "        data = data.to(device) #switch to GPU                                                                                                                                                                                                 \n",
    "        optimizer.zero_grad() #                                                                                                                                                                                                               \n",
    "        out = model(data.x, data.edge_index, data.batch).to(device)  # Perform a single forward pass                                                                                                                                          \n",
    "        out = out.cpu()\n",
    "        #yy = []                                                                                                                                                                                                                              \n",
    "        #for j in range(0,2*len(out),2):                                                                                                                                                                                                      \n",
    "        #    fuckk = data.y[j]; fuckj = data.y[j+1]                                                                                                                                                                                           \n",
    "        #    yy +=[[fuckk.item(),fuckj.item()]]                                                                                                                                                                                               \n",
    "        #yy = torch.tensor(yy).to(device)                                                                                                                                                                                                     \n",
    "        #loss = losss(out, yy).cpu() #compute the loss                                                                                                                                                                                        \n",
    "        outt+=[[out.detach().numpy()]]\n",
    "    return outt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766e0a37-c7f1-4069-83bc-4f721e72d195",
   "metadata": {},
   "outputs": [],
   "source": [
    "nepochs =  3\n",
    "train_metrics = {'mse':[], \"rmse\":[], 'mse_pi':[], 'rmse_pi':[], 'mse_p':[], 'rmse_p':[] }\n",
    "vall_metrics = {'mse':[], \"rmse\":[], 'mse_pi':[], 'rmse_pi':[], 'mse_p':[], 'rmse_p':[] }\n",
    "\n",
    "for epoch in range(nepochs): \n",
    "    '''\n",
    "    if epoch ==(nepochs-1):\n",
    "        model.eval()\n",
    "        outt = []\n",
    "        for i, data in enumerate(train_loader):\n",
    "            data = data.to(device) \n",
    "            out = model(data.x, data.edge_index, data.batch).to(device)\n",
    "            out = out.cpu()\n",
    "            outt+=[[out.detach().numpy()]]\n",
    "        #print(outt)\n",
    "        #break'''\n",
    "    #print(\"BEFORE TRAIN()\")                                                                                                                                                                                                                  \n",
    "    train()\n",
    "    #print(\"BEFORE TEST(TRAIN_LOADER)\")                                                                                                                                                                                                       \n",
    "    train_mse, train_rmse, train_mse_pi, train_rmse_pi, train_mse_p, train_rmse_p = test(train_loader)\n",
    "\n",
    "    train_metrics['mse'].append(train_mse)\n",
    "    train_metrics['rmse'].append(train_rmse)\n",
    "    train_metrics['mse_pi'].append(train_mse_pi)\n",
    "    train_metrics['rmse_pi'].append(train_rmse_pi)\n",
    "    train_metrics['mse_p'].append(train_mse_p)\n",
    "    train_metrics['rmse_p'].append(train_rmse_p)\n",
    "\n",
    "    #print(\"BEFORE TEST(VAL_LOADER)\")                                                                                                                                                                                                         \n",
    "    vall_mse, vall_rmse, vall_mse_pi, vall_rmse_pi, vall_mse_p, vall_rmse_p = test(val_loader)\n",
    "    #if epoch==0 or val_roc_auc >np.max(val_metrics[\"roc_auc\"]) :                                                                                                                                                                             \n",
    "    #    model_best_auc = model                                                                                                                                                                                                               \n",
    "    #    PATH = '/work/clas12/users/mfmce/CLAS12_Lambda_resolution_REU_2023/model_best_auc.pt'                                                                                                                                                \n",
    "    #    torch.save({                                                                                                                                                                                                                         \n",
    "    #        'epoch': epoch,                                                                                                                                                                                                                  \n",
    "    #        'model_state_dict': model.state_dict(),                                                                                                                                                                                          \n",
    "    #        'optimizer_state_dict': optimizer.state_dict(),                                                                                                                                                                                  \n",
    " #             'loss': loss,                                                                                                                                                                                                                  \n",
    "    #        }, PATH)                                                                                                                                                                                                                         \n",
    "\n",
    "    vall_metrics['mse'].append(vall_mse)\n",
    "    vall_metrics['rmse'].append(vall_rmse)\n",
    "    vall_metrics['mse_pi'].append(vall_mse)\n",
    "    vall_metrics['rmse_pi'].append(vall_mse)\n",
    "    vall_metrics['mse_p'].append(vall_mse)\n",
    "    vall_metrics['rmse_p'].append(vall_mse)\n",
    "    if epoch%9==0:\n",
    "        print(\"Epoch \",epoch,\" Train mse: \",train_mse,\" Train rmse: \",train_rmse,\" Train mse pion: \",train_mse_pi,\n",
    "              \" Train rmse pion: \",train_rmse_pi, \"Train mse proton:\",train_mse_p, \"Train rmse proton:\",train_rmse_p)\n",
    "        print(\"Epoch \",epoch,\" Validation mse: \",vall_mse,\" Validation rmse: \",vall_rmse,\" Validation mse pion: \",vall_mse_pi,\n",
    "              \" Validation rmse pion: \",vall_rmse_pi, \"Validation mse proton:\",vall_mse_p, \"Validation rmse proton:\", vall_rmse_p)\n",
    "    if epoch==(nepochs-1):\n",
    "        a = print_out()\n",
    "        print(\"Epoch \",epoch,\" Train mse: \",train_mse,\" Train rmse: \",train_rmse,\" Train mse pion: \",train_mse_pi,\n",
    "              \" Train rmse pion: \",train_rmse_pi, \"Train mse proton:\",train_mse_p, \"Train rmse proton:\",train_rmse_p)\n",
    "        print(\"Epoch \",epoch,\" Validation mse: \",vall_mse,\" Validation rmse: \",vall_rmse,\" Validation mse pion: \",vall_mse_pi,\n",
    "              \" Validation rmse pion: \",vall_rmse_pi, \"Validation mse proton:\",vall_mse_p, \"Validation rmse proton:\", vall_rmse_p) \n",
    "\n",
    "        #print(a)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = [i for i in range(len(train_metrics[\"mse\"]))] \n",
    "plt.figure()\n",
    "plt.title('Training epoch vs. MSE') \n",
    "plt.plot(epochs, train_metrics['mse']) \n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('MSE')\n",
    "\n",
    "\n",
    "plt.title('Validation epoch vs. MSE') \n",
    "plt.plot(epochs, vall_metrics['mse'])\n",
    "plt.xlabel('epoch') \n",
    "plt.ylabel('MSE') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e7b66b-8a2b-457e-bfe7-c70d68678a47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9072fc-85b4-4ccb-9f64-d3d20134d81e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efabd48c-9946-4a24-9908-274bea5021a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_x = []; p_x = []\n",
    "for i in range(len(a)):\n",
    "    for j in range(len(a[i][0])):\n",
    "        pi_x.append(a[i][0][j][0].item())\n",
    "        p_x.append(a[i][0][j][1].item()) \n",
    "\n",
    "pi_yy = [] \n",
    "p_yy = []\n",
    "\n",
    "pi_rec_y = []\n",
    "p_rec_y = []\n",
    "for i, data in enumerate(train_loader):\n",
    "    data = data#.to(device) #put to GPU\n",
    "    #break\n",
    "    for j in range(0,int(len(data.y)),2): \n",
    "        pi_yy.append(data.y[j].item())\n",
    "        p_yy.append(data.y[j+1].item())\n",
    "\n",
    "        #pi_rec_y.append(data.rec[j].item())\n",
    "       # p_rec_y.append(data.rec[j+1].item())\n",
    "    #for j in range(len(data.rec)):\n",
    "        #pi_rec_y.append(data.rec[j][0][0]) \n",
    "       # p_rec_y.append(data.rec[j][0][1])\n",
    "\n",
    "\n",
    "plott_pi = np.zeros((len(pi_x),2))\n",
    "plott_p = np.zeros((len(p_x),2))\n",
    "for i in range(len(pi_x)):\n",
    "    plott_pi[i][0] = pi_yy[i]\n",
    "    plott_pi[i][1] = pi_x[i]\n",
    "    #plott_pi[i][2] = pi_rec_y[i]\n",
    "    plott_p[i][0] = p_yy[i]\n",
    "    plott_p[i][1] = p_x[i]\n",
    "    #plott_p[i][2]  = p_rec_y[i]\n",
    "#plott_pi\n",
    "plt.figure\n",
    "plt.title('Expected (orange) vs predicted (blue) of Pion vertex') \n",
    "plt.axvline(x = np.mean(pi_x), color = 'blue')\n",
    "plt.axvline(x = np.mean(pi_yy), color = 'orange')\n",
    "plt.hist(x = plott_pi, histtype ='step', color = ['orange', 'blue'], bins = 500)\n",
    "plt.xlim((-6,0))\n",
    "#plt.hist(x = plott_pi, histtype ='bar', color = ['orange', 'blue'], bins = 30)\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Expected (orange) vs predicted (blue) of Proton vertex') \n",
    "plt.axvline(x = np.mean(p_x), color = 'blue')\n",
    "plt.axvline(x = np.mean(p_yy), color = 'orange')\n",
    "plt.hist(x = plott_p, histtype ='step', color = ['orange', 'blue'], bins = 100)\n",
    "plt.xlim((-10,10))\n",
    "#plt.hist(p_rec_y, color = 'green', alpha = .25, bins = 50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1de888-effb-497b-9ffd-bcc1e089350d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad0f911-a576-4a27-97c1-e5814e4da1ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
