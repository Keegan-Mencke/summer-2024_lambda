{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "parliamentary-clerk",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import awkward as ak\n",
    "import pandas as pd\n",
    "#import dask\n",
    "#import dask.dataframe as dd\n",
    "\n",
    "# I/O\n",
    "import uproot as ur\n",
    "import hipopy.hipopy as hp # <--- Package for reading in the hipo files\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Physics\n",
    "from particle import PDGID\n",
    "\n",
    "# Miscellaneous\n",
    "import os\n",
    "import sys #NOTE: ADDED\n",
    "import tqdm\n",
    "\n",
    "# ML Imports\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch_geometric as tg\n",
    "# HIPO bank reading and linking functions\n",
    "\n",
    "from torch_geometric.data import Data as dt\n",
    "\n",
    "def get_bank_keys(bank_name,all_keys,separator='_'):\n",
    "    \"\"\"\n",
    "    :description: Get list of the keys for given bank name from a list of all batch keys.\n",
    "    \n",
    "    :param: bank_name\n",
    "    :param: all_keys\n",
    "    :param: separator='_'\n",
    "    \n",
    "    :return: bank_keys\n",
    "    \"\"\"\n",
    "    bank_keys = []\n",
    "    for key in all_keys:\n",
    "        if key.startswith(bank_name+separator):\n",
    "            bank_keys.append(key)\n",
    "    return bank_keys\n",
    "        \n",
    "def get_event_table(bank_keys,event_num,batch,dtype=float):\n",
    "    \"\"\"\n",
    "    :description: Get a bank event table as a numpy array of shape (number of columns, number of rows).\n",
    "    \n",
    "    :param: bank_keys\n",
    "    :param: event_num\n",
    "    :param: batch\n",
    "    :param: dtype=float\n",
    "    \n",
    "    :return: bank_table\n",
    "    \"\"\"\n",
    "    bank_table = []\n",
    "    bank_table = np.moveaxis(np.array([batch[key][event_num] for key in bank_keys], dtype=dtype),[0,1],[1,0])\n",
    "    return bank_table\n",
    "\n",
    "def get_link_indices(event_table_rec_particle,event_table,pindex_idx=1):\n",
    "    \"\"\"\n",
    "    :description: Get index pairs linking entries in a bank back to entries in the 'REC::Particle' bank.\n",
    "    \n",
    "    :param: event_table_rec_particle\n",
    "    :param: event_table\n",
    "    :param: pindex_idx=1\n",
    "    \n",
    "    :return: link_indices\n",
    "    \"\"\"\n",
    "    \n",
    "    link_indices = []\n",
    "    nrec = np.shape(event_table_rec_particle)[0]\n",
    "    for rec_particle_idx in range(0,nrec):\n",
    "        for event_table_idx, el in enumerate(event_table[:,pindex_idx]):\n",
    "            if el==rec_particle_idx:\n",
    "                link_indices.append([rec_particle_idx,event_table_idx])\n",
    "    return np.array(link_indices,dtype=int) #NOTE: link_indices = [(event_table_idx,rec_particle_idx)]\n",
    "\n",
    "def get_parent_indices(mc_event_table,index_idx=0,parent_idx=4,daughter_idx=5):\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    \"\"\"\n",
    "    for mc_event_table_idx, index in enumerate(mc_event_table[:,index_idx]):\n",
    "        pass\n",
    "    pass\n",
    "#get_match_\n",
    "def get_match_indices(\n",
    "    rec_event_table,\n",
    "    mc_event_table,\n",
    "    rec_px_idx             = 1,\n",
    "    rec_py_idx             = 2,\n",
    "    rec_pz_idx             = 3,\n",
    "    rec_ch_idx             = 8,\n",
    "    mc_px_idx              = 6,\n",
    "    mc_py_idx              = 7,\n",
    "    mc_pz_idx              = 8,\n",
    "    mc_pid_idx             = 3,\n",
    "    mc_daughter_idx        = 5,\n",
    "    match_charge           = True,\n",
    "    require_no_mc_daughter = True,\n",
    "    enforce_uniqueness     = True,\n",
    "    ):\n",
    "    \n",
    "    # Set minimum\n",
    "    rec_final_state_min_idx = 1\n",
    "    mc_final_state_min_idx  = 3 #NOTE: MC::Lund bank is structured [e, p, q, e', all the other final state particles...]\n",
    "    \n",
    "    # Initialize index map\n",
    "    match_indices    = -np.ones((rec_event_table.shape[0],2),dtype=float)\n",
    "    match_indices[0] = [0,3] #NOTE: Always match first entry in REC::Particle to scattered electron in MC::Lund.\n",
    "\n",
    "    # Get REC::Particle info\n",
    "    rec_px    = rec_event_table[:,rec_px_idx]\n",
    "    rec_py    = rec_event_table[:,rec_py_idx]\n",
    "    rec_pz    = rec_event_table[:,rec_pz_idx]\n",
    "    rec_pT    = np.sqrt(np.square(rec_event_table[:,rec_px_idx])+np.square(rec_event_table[:,rec_py_idx]))\n",
    "    rec_p     = np.sqrt(np.square(rec_event_table[:,rec_px_idx])+np.square(rec_event_table[:,rec_py_idx])+np.square(rec_event_table[:,rec_pz_idx]))\n",
    "    rec_theta = np.array(rec_pz)\n",
    "    rec_theta = np.arctan(rec_pT,rec_theta)\n",
    "    rec_phi   = np.arctan2(rec_py,rec_px)\n",
    "    \n",
    "    # Get MC::Lund info\n",
    "    mc_px    = mc_event_table[:,mc_px_idx]\n",
    "    mc_py    = mc_event_table[:,mc_py_idx]\n",
    "    mc_pz    = mc_event_table[:,mc_pz_idx]\n",
    "    mc_pT    = np.sqrt(np.square(mc_event_table[:,mc_px_idx])+np.square(mc_event_table[:,mc_py_idx]))\n",
    "    mc_p     = np.sqrt(np.square(mc_event_table[:,mc_px_idx])+np.square(mc_event_table[:,mc_py_idx])+np.square(mc_event_table[:,mc_pz_idx]))\n",
    "    mc_theta = np.array(mc_pz)\n",
    "    mc_theta = np.arctan(mc_pT,mc_theta)\n",
    "    mc_phi   = np.arctan2(mc_py,mc_px)\n",
    "\n",
    "    # Loop rec particles\n",
    "    for rec_idx, rec_part in enumerate(rec_event_table):\n",
    "        \n",
    "        # Start with final state particles past scattered electron\n",
    "        if rec_idx<rec_final_state_min_idx: continue\n",
    "        \n",
    "        # Get REC::Particle charge\n",
    "        rec_ch = rec_event_table[rec_idx,rec_ch_idx]\n",
    "        \n",
    "        # Loop mc particles\n",
    "        mc_match_idx = -1\n",
    "        min_domega   = 9999\n",
    "        for mc_idx, mc_part in enumerate(mc_event_table):\n",
    "            \n",
    "            # Start with final state particles past scattered electron\n",
    "            if mc_idx<mc_final_state_min_idx:\n",
    "                continue\n",
    "            \n",
    "            # Enforce unique matching\n",
    "            if enforce_uniqueness and mc_idx in match_indices[:,1]:\n",
    "                continue\n",
    "            \n",
    "            # Match charge and require that the MC particle be final state (no daughters)\n",
    "            if match_charge and rec_ch!=PDGID(mc_event_table[mc_idx,mc_pid_idx]).charge:\n",
    "                continue\n",
    "            if require_no_mc_daughter and mc_event_table[mc_idx,mc_daughter_idx]!=0:\n",
    "                continue\n",
    "                \n",
    "            # Get angular and momentum differences\n",
    "            dp     = np.abs(rec_p[rec_idx]     - mc_p[mc_idx])\n",
    "            dtheta = np.abs(rec_theta[rec_idx] - mc_theta[mc_idx])\n",
    "            dphi   = np.abs(rec_phi[rec_idx]   - mc_phi[mc_idx]) if np.abs(rec_phi[rec_idx] - mc_phi[mc_idx])<np.pi else 2*np.pi-np.abs(rec_phi[rec_idx] - mc_phi[mc_idx])\n",
    "            domega = dp**2 + dtheta**2 + dphi**2\n",
    "            \n",
    "            # Reset angular, momentum minimum difference\n",
    "            if domega<min_domega:\n",
    "                min_domega   = domega\n",
    "                mc_match_idx = mc_idx\n",
    "                \n",
    "        # Append matched index pair\n",
    "        match_indices[rec_idx] = [rec_idx,mc_match_idx]\n",
    "        \n",
    "    return np.array(match_indices,dtype=int) #NOTE: IMPORTANT!\n",
    "\n",
    "def get_info(base_indices,link_indices,bank_entry_indices,bank_event_table):\n",
    "    \"\"\"\n",
    "    :description: Get selected entry info from other banks linked to REC::Particle.\n",
    "    \n",
    "    :param: base_indices\n",
    "    :param: link_indices #NOTE: if None assume bank is REC::Particle and use identity map\n",
    "    :param: bank_entry_indices\n",
    "    :param: bank_event_table\n",
    "    \n",
    "    :return: bank_info as awkward.Array\n",
    "    \"\"\"\n",
    "    if link_indices is None:\n",
    "        bank_info = []\n",
    "        for base_idx in base_indices:\n",
    "            base_info = bank_event_table[base_idx,bank_entry_indices]\n",
    "            bank_info.append([base_info])\n",
    "            \n",
    "        return ak.Array(bank_info)\n",
    "            \n",
    "    bank_info = []\n",
    "    for base_idx in base_indices:\n",
    "        base_info = []\n",
    "        for rec_particle_idx, link_idx in link_indices:\n",
    "            if rec_particle_idx==base_idx:\n",
    "                base_info.append(bank_event_table[link_idx,bank_entry_indices]) #NOTE: INDICES HAVE TO BE INTEGERS...COULD ADD CHECK...\n",
    "        if len(base_info)==0: #NOTE: Address case that no matches exist between banks\n",
    "            base_info.append(np.zeros((len(bank_entry_indices),)))\n",
    "        bank_info.append(base_info)\n",
    "    \n",
    "    return ak.Array(bank_info)\n",
    "\n",
    "def get_truth_info(base_indices,match_indices,truth_entry_indices,mc_event_table):\n",
    "    \"\"\"\n",
    "    :description: Get selected entry info from other banks linked to REC::Particle.\n",
    "    \n",
    "    :param: base_indices\n",
    "    :param: link_indices #NOTE: if None assume bank is REC::Particle and use identity map\n",
    "    :param: bank_entry_indices\n",
    "    :param: bank_event_table\n",
    "    \n",
    "    :return: bank_info as awkward.Array\n",
    "    \"\"\"\n",
    "    \n",
    "    bank_info = []\n",
    "    for base_idx in base_indices:\n",
    "        base_info = []\n",
    "        for rec_particle_idx, match_idx in match_indices:\n",
    "            if rec_particle_idx==base_idx:\n",
    "                base_info.append(mc_event_table[match_idx,truth_entry_indices]) #NOTE: INDICES HAVE TO BE INTEGERS...COULD ADD CHECK...\n",
    "        if len(base_info)==0: #NOTE: Address case that no matches exist between banks\n",
    "            base_info.append(np.zeros((len(truth_entry_indices),)))\n",
    "        bank_info.append(base_info)\n",
    "    \n",
    "    return ak.Array(bank_info)\n",
    "\n",
    "def check_has_decay(rec_particle_event_table,mc_lund_event_table,match_indices,decay,\n",
    "                    rec_particle_pid_idx=0,mc_lund_pid_idx=3,mc_lund_parent_idx=4,mc_lund_daughter_idx=5):\n",
    "    \n",
    "    \"\"\"\n",
    "    :description: Check if specified decay is present in MC::Lund bank and the decay daughters are\n",
    "        matched to particles of the same pid in REC::Particle\n",
    "    \n",
    "    :param: rec_particle_event_table\n",
    "    :param: mc_lund_event_table\n",
    "    :param: match_indices\n",
    "    :param: decay\n",
    "    :param: rec_particle_pid_idx = 0\n",
    "    :param: mc_lund_pid_idx      = 3\n",
    "    :param: mc_lund_parent_idx   = 4\n",
    "    :param: mc_lund_daughter_idx = 5\n",
    "    \n",
    "    :return: boolean has_decay\n",
    "    \"\"\"\n",
    "    \n",
    "    has_decay = False\n",
    "    decay_indices = None\n",
    "    rec_indices = [-1 for i in range(len(decay[1]))] #NOTE: This assumes a 1-level decay...#TODO: Write more robust algorithm.\n",
    "    if np.max(match_indices[:,-1])==-1: return has_decay, rec_indices #NOTE: This is the case of no matches at all.\n",
    "    \n",
    "    # Check if parent pid is in MC::Lund\n",
    "    if not decay[0] in mc_lund_event_table[:,mc_lund_pid_idx]: return has_decay, rec_indices\n",
    "    \n",
    "    # Loop MC::Lund to find parent\n",
    "    for parent_idx, parent_pid in enumerate(mc_lund_event_table[:,mc_lund_pid_idx]):\n",
    "        if parent_pid==decay[0]:\n",
    "#             print(\"DEBUGGING: found parent_pid == \",decay[0])\n",
    "            \n",
    "            # Check daughter pids in MC::Lund\n",
    "            daughter_idx     = int(mc_lund_event_table[parent_idx,mc_lund_daughter_idx])-1 #NOTE: -1 is important because Lund index begins at 1.\n",
    "            try:\n",
    "                daughter_pids    = mc_lund_event_table[daughter_idx:daughter_idx+len(decay[1]),mc_lund_pid_idx]\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(\"DEBUGGING: np.shape(mc_lund_event_table) = \",np.shape(mc_lund_event_table))\n",
    "                print(\"DEBUGGING: daughter_idx        = \",daughter_idx)\n",
    "                print(\"DEBUGGING: decay = \",decay)\n",
    "                raise Exception\n",
    "            daughter_parents = mc_lund_event_table[daughter_idx:daughter_idx+len(decay[1]),mc_lund_parent_idx]\n",
    "            daughter_parents -= 1 #NOTE: Important because Lund index begins at 1.\n",
    "            if np.all(daughter_parents==parent_idx) and np.all(daughter_pids==decay[1]): #NOTE: this relies on input arrays being np...\n",
    "                decay_indices = [parent_idx,[daughter_idx+i for i in range(len(decay[1]))]]\n",
    "                rec_indices = [-1 for i in range(len(decay[1]))]#NOTE: Reset in case you have two not fully matched decays...unlikely but possible.\n",
    "                \n",
    "                # Now check that there is a match of the same pid in REC::Particle\n",
    "                num_matched_daughters = 0\n",
    "                num_daughters         = len(decay[1])\n",
    "                for decay_idx, mc_idx in enumerate(decay_indices[1]):\n",
    "                    for el in match_indices:\n",
    "                        if el[1]==mc_idx:\n",
    "                            rec_idx = el[0]\n",
    "                            if rec_particle_event_table[rec_idx,rec_particle_pid_idx] == decay[1][decay_idx]:\n",
    "                                num_matched_daughters += 1\n",
    "                                rec_indices[decay_idx] = rec_idx #NOTE: That this is the actual index beginning at 0.\n",
    "#                 print(\"DEBUGGING: num_matched_daughters = \",num_matched_daughters)\n",
    "#                 print(\"DEBUGGING: decay_indices = \",decay_indices)\n",
    "                if num_matched_daughters == num_daughters:\n",
    "                    has_decay = True\n",
    "    \n",
    "    return has_decay, rec_indices\n",
    "\n",
    "# Select requested rows from REC::Particle data\n",
    "def get_sub_array(arr,indices):\n",
    "    \n",
    "    \"\"\"\n",
    "    :description: Get sub array at indices along axis 1.\n",
    "    \n",
    "    :param: arr\n",
    "    :param: indices\n",
    "    \n",
    "    :return: np.array new_arr\n",
    "    \"\"\"\n",
    "    \n",
    "    new_array = []\n",
    "    for i in indices:\n",
    "        new_array.append(arr[:,i])\n",
    "    new_array = np.moveaxis(np.array(new_array),[0,1],[1,0])\n",
    "\n",
    "    return new_array\n",
    "\n",
    "def replace_pids(arr,pid_map,pid_i=0):\n",
    "    \"\"\"\n",
    "    :description: Replace pids in given array roughly following scheme described in arxiv:1810.05165.\n",
    "    \n",
    "    :param: arr masked ndarray with dtype=float\n",
    "    :param: pid_i last depth index for pids in arr\n",
    "    \"\"\"\n",
    "    \n",
    "    if 'int' in str(arr.dtype):\n",
    "        print(\" *** ERROR *** array passed to replace_pids should not have dtype==int\")\n",
    "        return\n",
    "    \n",
    "    for key in pid_map:\n",
    "        arr[:,pid_i] = np.where(arr[:,pid_i]==key,\n",
    "                                  pid_map[key],\n",
    "                                  arr[:,pid_i])\n",
    "\n",
    "def preprocess(x):\n",
    "    \"\"\"\n",
    "    :description: Run preprocessing on input array.\n",
    "    \n",
    "    :param: x\n",
    "    \n",
    "    :return: new_x\n",
    "    \"\"\"\n",
    "    #NOTE: Assume indices go 0-6 : pid, px, py, pz, beta, chi2pid, status\n",
    "    \n",
    "    pid_map = {\n",
    "        22:0.0,\n",
    "        11:-1.0,\n",
    "        -11:1.0,\n",
    "        2212:0.8,\n",
    "        -2212:-0.8,\n",
    "        2112:0.5,\n",
    "        111:0.1,\n",
    "        211:0.6,\n",
    "        -211:-0.6,\n",
    "        311:0.3,\n",
    "        321:0.4,\n",
    "        -321:-0.4,\n",
    "        45:0.0\n",
    "    }\n",
    "    \n",
    "    pid_idx, px_idx, py_idx, pz_idx, beta_idx, chi2pid_idx, status_idx = [i for i in range(np.shape(x)[-1])]\n",
    "    \n",
    "    # Reassign PIDs\n",
    "    replace_pids(x,pid_map,pid_i=0)\n",
    "    \n",
    "    # Compute new arrays\n",
    "    pT    = np.sqrt(np.add(np.square(x[:,px_idx]),np.square(x[:,py_idx])))\n",
    "    phi   = np.arctan2(x[:,py_idx],x[:,px_idx])\n",
    "    theta = np.divide(pT,x[:,pz_idx])\n",
    "    beta  = np.log(x[:,beta_idx])\n",
    "    \n",
    "    #TODO: Compute event level differences and normalize: pT, phi, theta, beta (apply lognorm first though...)\n",
    "    pT    -= pT.mean()\n",
    "    pT    /= np.abs(pT).max() if np.abs(pT).max() > 0.0 else 1.0\n",
    "    phi   -= phi.mean()\n",
    "    phi   /= np.abs(phi).max() if np.abs(phi).max() > 0.0 else 1.0\n",
    "    theta -= theta.mean()\n",
    "    theta /= np.abs(theta).max() if np.abs(theta).max() > 0.0 else 1.0\n",
    "    beta  -= beta.mean()\n",
    "    beta  /= np.abs(beta).max() if np.abs(beta).max() > 0.0 else 1.0\n",
    "    \n",
    "    # Reset px, py, pz, beta -> pT, phi, theta, beta\n",
    "    x[:,px_idx]   = pT\n",
    "    x[:,py_idx]   = phi\n",
    "    x[:,pz_idx]   = theta\n",
    "    x[:,beta_idx] = beta\n",
    "    \n",
    "#     # Preprocess pT, phi, theta\n",
    "#     x[:,px_idx] /= 10.0\n",
    "#     x[:,py_idx] /= np.pi\n",
    "#     x[:,pz_idx] /= np.pi\n",
    "    \n",
    "#     # Preprocess beta variable\n",
    "#     x[:,beta_idx] -= 1\n",
    "    \n",
    "    # Preprocess chi2pid\n",
    "    chi2_max, chi2_default, chi2_replacement   = 10, 9999, 10 #NOTE: DEBUGGING: USED TO BE >=chi2_default below!\n",
    "    x[:,chi2pid_idx]  = np.where(x[:,chi2pid_idx]>=chi2_default, chi2_replacement, x[:,chi2pid_idx])\n",
    "    x[:,chi2pid_idx] /= chi2_max #NOTE: IMPORTANT!  NEEDS TO BE AFTER REPLACEMENT OF MAX ABOVE!\n",
    "    \n",
    "    # Preprocess status variable\n",
    "    x[:,status_idx] /= 5000\n",
    "    \n",
    "    # Reassign all data values that are NaN or Inf to zero\n",
    "    x = np.where(np.isnan(x), 0.0, x)\n",
    "    x = np.where(np.isinf(x), 0.0, x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def preprocess_rec_traj(x):\n",
    "    \"\"\"\n",
    "    :description: Run preprocessing on input array assuming it is full matrix of REC::Traj bank.\n",
    "    \n",
    "    :param: x\n",
    "    \n",
    "    :return: new_x\n",
    "    \"\"\"\n",
    "    #NOTE: Assume indices go 0-10 : pindex, index, detector, layer, x, y, z, cx, cy, cz, path\n",
    "    \n",
    "    pindex_idx, index_idx, detector_idx, layer_idx, x_idx, y_idx, z_idx, cx_idx, cy_idx, cz_idx, path_idx = [i for i in range(np.shape(x)[-1])]\n",
    "    \n",
    "    # Preprocess row info\n",
    "#     x[:,x_idx]    -= 0.0\n",
    "    x[:,x_idx]    /= 1500.0\n",
    "#     x[:,y_idx]    -= 0.0\n",
    "    x[:,y_idx]    /= 1500.0\n",
    "    x[:,z_idx]    -= 1500.0/2\n",
    "    x[:,z_idx]    /= 1500.0\n",
    "#     x[:,cx_idx]   -= 0.0\n",
    "#     x[:,cx_idx]   /= 1.0\n",
    "#     x[:,cy_idx]   -= 0.0\n",
    "#     x[:,cy_idx]   /= 1.0\n",
    "    x[:,cz_idx]   -= 1.0\n",
    "    x[:,cz_idx]   /= 2.0\n",
    "    x[:,path_idx] -= 1500.0/2\n",
    "    x[:,path_idx] /= 1500.0\n",
    "    \n",
    "    # Select rows to take #NOTE: Do this after preprocessing so indices make sense\n",
    "    indices = [x_idx, y_idx, z_idx, cx_idx, cy_idx, cz_idx, path_idx]\n",
    "    x = np.take(x,indices,axis=1)\n",
    "    \n",
    "    # Reassign all data values that are NaN or Inf to zero\n",
    "    x = np.where(np.isnan(x), 0.0, x)\n",
    "    x = np.where(np.isinf(x), 0.0, x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def get_links_rec_traj(x):\n",
    "    \n",
    "    pindex = 0\n",
    "    link_indices = []\n",
    "    prev_el = -10\n",
    "    for idx, el in enumerate(x[:,pindex]):\n",
    "        if el != prev_el:\n",
    "            link_indices.append([idx])\n",
    "        else:\n",
    "            link_indices[-1].append(idx)\n",
    "        prev_el = el\n",
    "        \n",
    "    return link_indices\n",
    "\n",
    "def get_edge_index_rec_traj(x):\n",
    "    \n",
    "    link_indices = get_links_rec_traj(x)\n",
    "    \n",
    "    edge_index = torch.tensor([[i,j] for el_ in link_indices for i in el_ for j in el_],dtype=torch.long)\n",
    "        \n",
    "    return edge_index \n",
    "\n",
    "x___ = torch.tensor([[i//3] for i in range(15)],dtype=torch.long)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-revelation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sexual-ghana",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revolutionary-george",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "architectural-skiing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.408587798038327"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.gauss(-2.598, 2*3.394)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "basic-cincinnati",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['MC::Lund_index', 'MC::Lund_lifetime', 'MC::Lund_type', 'MC::Lund_pid', 'MC::Lund_parent', 'MC::Lund_daughter', 'MC::Lund_px', 'MC::Lund_py', 'MC::Lund_pz', 'MC::Lund_energy', 'MC::Lund_mass', 'MC::Lund_vx', 'MC::Lund_vy', 'MC::Lund_vz', 'REC::Particle_pid', 'REC::Particle_px', 'REC::Particle_py', 'REC::Particle_pz', 'REC::Particle_vx', 'REC::Particle_vy', 'REC::Particle_vz', 'REC::Particle_vt', 'REC::Particle_charge', 'REC::Particle_beta', 'REC::Particle_chi2pid', 'REC::Particle_status', 'REC::Traj_pindex', 'REC::Traj_index', 'REC::Traj_detector', 'REC::Traj_layer', 'REC::Traj_x', 'REC::Traj_y', 'REC::Traj_z', 'REC::Traj_cx', 'REC::Traj_cy', 'REC::Traj_cz', 'REC::Traj_path'])\n",
      "dict_keys(['REC::Kinematics_idxe', 'REC::Kinematics_idxp', 'REC::Kinematics_idxpi', 'REC::Kinematics_Q2', 'REC::Kinematics_nu', 'REC::Kinematics_W', 'REC::Kinematics_x', 'REC::Kinematics_y', 'REC::Kinematics_z', 'REC::Kinematics_xF', 'REC::Kinematics_mass'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MyDataset(19743)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.data import Dataset, download_url, InMemoryDataset\n",
    "\n",
    "step = 40000 \n",
    "for batch in hp.iterate(['/volatile/clas12/users/mfmce/mc_jobs_rga_vtx_2_12_24/skim_50nA_OB_job_3313_0.hipo'],banks=[\"MC::Lund\", \"REC::Particle\", \"REC::Traj\"],step=step):\n",
    "    print(batch.keys()) \n",
    "    #batch.keys()\n",
    "    dic = batch.keys() \n",
    "    break  \n",
    "    \n",
    "for battch in hp.iterate(['/volatile/clas12/users/mfmce/mc_jobs_rga_vtx_2_12_24/analysis2/kinematics_out_skim_50nA_OB_job_3313_0.hipo'],banks=[\"REC::Kinematics\"],step=step):\n",
    "    print(battch.keys()) \n",
    "    #batch.keys()\n",
    "    dic = battch.keys() \n",
    "    break \n",
    "#\n",
    "\n",
    "all_keys            = list(batch.keys())\n",
    "rec_particle_name   = 'REC::Particle'\n",
    "rec_particle_keys   = get_bank_keys(rec_particle_name,all_keys)\n",
    "rec_traj_name       = 'REC::Traj'\n",
    "rec_traj_keys       = get_bank_keys(rec_traj_name,all_keys)\n",
    "rec_kinematics_name = 'REC::Kinematics' \n",
    "rec_kinematics_keys = get_bank_keys(rec_kinematics_name,all_keys)\n",
    "mc_lund_name        = 'MC::Lund'\n",
    "mc_lund_keys        = get_bank_keys(mc_lund_name,all_keys) \n",
    "\n",
    "rec_kinematics_keys = ['REC::Kinematics_idxe', 'REC::Kinematics_idxp', 'REC::Kinematics_idxpi', 'REC::Kinematics_Q2', \n",
    "                       'REC::Kinematics_nu', 'REC::Kinematics_W', 'REC::Kinematics_x', 'REC::Kinematics_y', 'REC::Kinematics_z', 'REC::Kinematics_xF', 'REC::Kinematics_mass']\n",
    "#fulll = [] \n",
    "tst = []\n",
    "y=[]\n",
    "#third is list of graphss \n",
    "third = []\n",
    "#j is proton, kk is pion\n",
    "\n",
    "\n",
    "kinn = [] \n",
    "idkkk =[]\n",
    "for i in range(step):\n",
    "    # Get REC::Particle bank\n",
    "    rec_particle_event_table = get_event_table(rec_particle_keys,i,batch,dtype=float)\n",
    "\n",
    "    # Get REC::Traj bank\n",
    "    rec_traj_event_table = get_event_table(rec_traj_keys,i,batch,dtype=float)\n",
    "\n",
    "    # Get REC::Kinematics bank\n",
    "    rec_kinematics_event_table = get_event_table(rec_kinematics_keys,i,battch,dtype=float)\n",
    "\n",
    "    # Get MC::Lund bank and MC->REC matching indices\n",
    "    mc_lund_event_table = get_event_table(mc_lund_keys,i,batch,dtype=float)\n",
    "    match_indices  = get_match_indices(rec_particle_event_table,mc_lund_event_table)\n",
    "    \n",
    "    #getting the index of where the electron proton and pion r \n",
    "    savee = batch['REC::Particle_pid'][i]\n",
    "    j = savee.index(2212); kk = savee.index(-211); elc = savee.index(11) #elc is electron, used for checking that it matches up, j is proton, kk is pionn \n",
    "    \n",
    "    #making sure that it is not bad (for the match) #if is bad then lots more stuff to do \n",
    "    if match_indices[kk][1]!=-1:\n",
    "        if (np.sqrt(batch['MC::Lund_px'][i][match_indices[kk][1]]**2+batch['MC::Lund_py'][i][match_indices[kk][1]]**2+batch['MC::Lund_pz'][i][match_indices[kk][1]]**2)<1):\n",
    "            track_hit = []\n",
    "            indexp = [index for (index, item) in enumerate(batch['REC::Traj_pindex'][i]) if item == j]\n",
    "            indexpi = [index for (index, item) in enumerate(batch['REC::Traj_pindex'][i]) if item == kk]\n",
    "            #get all the data we need here. \n",
    "\n",
    "            totalpos =[ [batch['REC::Traj_x'][i][ii] for ii in indexpi], [ batch['REC::Traj_y'][i][ii] for ii in indexpi], [ batch['REC::Traj_z'][i][ii] for ii in indexpi],\n",
    "                      [batch['REC::Traj_cx'][i][ii] for ii in indexpi], [ batch['REC::Traj_cy'][i][ii] for ii in indexpi], [ batch['REC::Traj_cz'][i][ii] for ii in indexpi]]\n",
    "\n",
    "\n",
    "            s = 0\n",
    "            ss =0\n",
    "            for dd in range(len(indexpi)):\n",
    "                track_hit += [[batch['REC::Traj_x'][i][indexpi[dd]], batch['REC::Traj_y'][i][indexpi[dd]], batch['REC::Traj_z'][i][indexpi[dd]],\n",
    "                             batch['REC::Traj_cx'][i][indexpi[dd]], batch['REC::Traj_cy'][i][indexpi[dd]], batch['REC::Traj_cz'][i][indexpi[dd]],\n",
    "                               batch['REC::Particle_px'][i][kk], batch['REC::Particle_py'][i][kk], batch['REC::Particle_pz'][i][kk]]]\n",
    "                s +=1\n",
    "            #track_hit+=[[batch['REC::Particle_px'][i][kk], batch['REC::Particle_py'][i][kk], batch['REC::Particle_pz'][i][kk],\n",
    "             #           batch['REC::Particle_vx'][i][kk], batch['REC::Particle_vy'][i][kk], batch['REC::Particle_vz'][i][kk]]]\n",
    "            ss =0\n",
    "            for dd in range(len(indexp)): \n",
    "                track_hit += [[batch['REC::Traj_x'][i][indexp[dd]], batch['REC::Traj_y'][i][indexp[dd]], batch['REC::Traj_z'][i][indexp[dd]],\n",
    "                              batch['REC::Traj_cx'][i][j], batch['REC::Traj_cy'][i][j], batch['REC::Traj_cz'][i][j],\n",
    "                              batch['REC::Particle_px'][i][j], batch['REC::Particle_py'][i][j], batch['REC::Particle_pz'][i][j]]]\n",
    "\n",
    "                ss+=1 \n",
    "\n",
    "            #y = [batch['MC::Lund_pz'][i][match_indices[kk][1]], batch['MC::Lund_pz'][i][match_indices[j][1]]] \n",
    "            r = np.sqrt(batch['MC::Lund_px'][i][match_indices[kk][1]]**2+batch['MC::Lund_py'][i][match_indices[kk][1]]**2+batch['MC::Lund_pz'][i][match_indices[kk][1]]**2)\n",
    "            theta = np.arccos(batch['MC::Lund_pz'][i][match_indices[kk][1]]/r)\n",
    "            \n",
    "            phi = np.arctan2(batch['MC::Lund_py'][i][match_indices[kk][1]],batch['MC::Lund_px'][i][match_indices[kk][1]])\n",
    "            y = [phi]  \n",
    "\n",
    "            #track_hit += [[np.sqrt(batch['REC::Particle_px'][i][kk]**2+batch['REC::Particle_py'][i][kk]**2+ batch['REC::Particle_pz'][i][kk]**2)]]\n",
    "\n",
    "            start = []\n",
    "            end = []\n",
    "            for gg in range(s-1):\n",
    "                start.append(gg)\n",
    "                end.append(gg+1)\n",
    "            for ggg in range(ss-1):\n",
    "                start.append(s+ggg)\n",
    "                end.append(s+ggg+1)\n",
    "            #fourth = dt(x=torch.tensor(track_hit), edge_index = torch.tensor([start, end]), y = torch.tensor(y))\n",
    "            fourth = dt(x=torch.tensor(track_hit), edge_index = torch.tensor([start, end]), y = torch.tensor(y))\n",
    "           # fourth.kinematics = [battch['REC::Kinematics_Q2'][i][0], battch['REC::Kinematics_nu'][i][0], battch['REC::Kinematics_W'][i][0], battch['REC::Kinematics_x'][i][0],  \n",
    "            #                     battch['REC::Kinematics_y'][i][0], battch['REC::Kinematics_z'][i][0], battch['REC::Kinematics_xF'][i][0], battch['REC::Kinematics_mass'][i][0]]\n",
    "            rr = np.sqrt(batch['REC::Particle_px'][i][kk]**2+batch['REC::Particle_py'][i][kk]**2+batch['REC::Particle_pz'][i][kk]**2) \n",
    "            thetaa = np.arccos(batch['REC::Particle_pz'][i][kk]/rr) \n",
    "            phii = np.arctan2(batch['REC::Particle_py'][i][kk], batch['REC::Particle_px'][i][kk])\n",
    "            fourth.rec  = [phii]\n",
    "            #idkkk+=[[batch['REC::Particle_vz'][i][kk], batch['REC::Particle_vz'][i][j]]]\n",
    "            third+= [fourth]\n",
    "        #third += [dt(x=torch.tensor(track_hit), edge_index = torch.tensor([start, end]), y = torch.tensor(y))] \n",
    "       # kinn+= [[battch['REC::Kinematics_Q2'][i][0], battch['REC::Kinematics_nu'][i][0], battch['REC::Kinematics_W'][i][0], battch['REC::Kinematics_x'][i][0],  \n",
    "       #    battch['REC::Kinematics_y'][i][0], battch['REC::Kinematics_z'][i][0], battch['REC::Kinematics_xF'][i][0], battch['REC::Kinematics_mass'][i][0]]] \n",
    "    \n",
    "                    \n",
    "    \n",
    "    #saving the kinamatics \n",
    "data_list = third\n",
    "root = '/work/clas12/users/mencke/ttest_momcut_phi_30000'\n",
    "class MyDataset(InMemoryDataset):\n",
    "    def __init__(self, root, data_list, transform=None):\n",
    "        self.data_list = data_list\n",
    "        super().__init__(root, transform) \n",
    "        self.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return 'data.pt'\n",
    " \n",
    "    def process(self):\n",
    "        self.save(self.data_list, self.processed_paths[0])\n",
    "\n",
    "MyDataset(root, third) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-laptop",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/work/clas12/users/mencke/pi_phi_polar', trying to get the polor corrdinate phi, \n",
    "root = '/work/clas12/users/mencke/pi_theta_polar', trying to get the polor corrdinate theta,\n",
    "root = '/work/clas12/users/mencke/pi_r_polar', trying to get the polor corrdinate theta\n",
    "\n",
    "ttest_momcut_r_30000. momentum cut testing, [[batch['REC::Traj_x'][i][indexpi[dd]], batch['REC::Traj_y'][i][indexpi[dd]], batch['REC::Traj_z'][i][indexpi[dd]],\n",
    "                             batch['REC::Traj_cx'][i][indexpi[dd]], batch['REC::Traj_cy'][i][indexpi[dd]], batch['REC::Traj_cz'][i][indexpi[dd]],\n",
    "                               batch['REC::Particle_px'][i][kk], batch['REC::Particle_py'][i][kk], batch['REC::Particle_pz'][i][kk]]] for both pion and proton\n",
    "\n",
    "root = '/work/clas12/users/mencke/ttest_momcut_theta_30000' \n",
    "oot = '/work/clas12/users/mencke/ttest_momcut_phi_30000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-merit",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perceived-vegetable",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
