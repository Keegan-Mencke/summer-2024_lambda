{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "national-envelope",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device =  cuda:0\n",
      "DEBUGGING: torch.cuda.is_available() =  True\n",
      "Number of training graphs: 7231\n",
      "Number of validation graphs: 904\n",
      "Number of test graphs: 904\n"
     ]
    }
   ],
   "source": [
    "#import os\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import numpy.ma as ma \n",
    "import awkward as ak\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch_geometric as tg\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "#import torch\n",
    "from torch_geometric.data import InMemoryDataset, download_url\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "#NOTE: NEW 2/20/23 \n",
    "from typing import List, Union\n",
    "\n",
    "from torch_geometric.data import Data, HeteroData\n",
    "from torch_geometric.data.datapipes import functional_transform\n",
    "from torch_geometric.transforms import BaseTransform \n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "root = '/work/clas12/users/mencke/pyg_test_rec_traj_dataset_111'\n",
    "class MyOwnDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.load(self.processed_paths[0])\n",
    "        # For PyG<2.4:\n",
    "        # self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['some_file_1', 'some_file_2']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "\n",
    "    def process(self):\n",
    "        # Read data into huge `Data` list.\n",
    "        data_list = None\n",
    "\n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(data) for data in data_list]\n",
    "\n",
    "        self.save(data_list, self.processed_paths[0])\n",
    "        # For PyG<2.4:\n",
    "        # torch.save(self.collate(data_list), self.processed_paths[0])\n",
    "\n",
    "# Create PyG Dataset\n",
    "#root = '/work/clas12/users/mfmce/pyg_test_rec_traj_dataset_5_28_24/' # 3_14_24 #OLD\n",
    "dataset = MyOwnDataset(\n",
    "            root,\n",
    "            transform=None, #T.Compose([T.ToUndirected(),T.KNNGraph(k=6)]),\n",
    "            pre_transform=None,\n",
    "            pre_filter=None\n",
    "        )\n",
    "dataset\n",
    "\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import GraphConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.nn.norm import GraphNorm, BatchNorm \n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GCN, self).__init__()\n",
    "#         torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)#.jittable() #NOTE: NEEDED FOR DEPLOYMENT IN CMAKE\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)#.jittable()\n",
    "        #self.block2 = nn.DataParallel(self.block2)\n",
    "        #self.conv2 = torch.nn.DataParallel(self.conv2) #this was trying the parallization thing. \n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)#.jittable()\n",
    "        #self.conv3 = torch.nn.DataParallel(self.conv3)\n",
    "        self.lin1 = Linear(hidden_channels, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, hidden_channels)\n",
    "        self.lin3 = Linear(hidden_channels, out_channels)\n",
    "        self.bn1 = torch_geometric.nn.norm.GraphNorm(hidden_channels)\n",
    "        self.bn2 = torch_geometric.nn.norm.GraphNorm(hidden_channels)\n",
    "        self.bn3 = torch_geometric.nn.norm.GraphNorm(hidden_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch): \n",
    "        # 1. Obtain node embeddings \n",
    "#         print(\"x = \",x)\n",
    "#         print(\"DEBUGGING: in GCN: begin: x.requires_grad = \",x.requires_grad)\n",
    "        x = self.conv1(x, edge_index) #input layer\n",
    "#         print(\"DEBUGGING: in GCN: self.conv1(x, edge_index): x.requires_grad = \",x.requires_grad)\n",
    "        x = self.bn1(x) #normalize it\n",
    "#         print(\"DEBUGGING: in GCN: self.bn2(x): x.requires_grad = \",x.requires_grad)\n",
    "#         print(\"self.conv1(x,edge_index) = \",x)\n",
    "        x = x.relu() #activation\n",
    "#         x = torch.nn.function.elu(x)\n",
    "#         print(\"DEBUGGING: in GCN: x.relu(): x.requires_grad = \",x.requires_grad)\n",
    "#         print(\"x.relu() = \",x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.bn2(x)\n",
    "#         print(\"DEBUGGING: in GCN: self.bn2(x): x.requires_grad = \",x.requires_grad)\n",
    "#         print(\"self.conv2(x,edge_index) = \",x)\n",
    "        x = x.relu() \n",
    "#         print(\"x.relu() = \",x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = self.bn3(x)\n",
    "#         print(\"self.conv3(x,edge_index) = \",x) \n",
    "#         print(\"DEBUGGING: in GCN: self.bn3(x): x.requires_grad = \",x.requires_grad)\n",
    "\n",
    "#         # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch) #what is this for.           # [batch_size, hidden_channels]\n",
    "#         print(\"self.conv2(global_mean_pool(x, batch)) = \",x)\n",
    "#         print(\"DEBUGGING: in GCN: global_mean_pool(x): x.requires_grad = \",x.requires_grad)\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training) #for overfitting\n",
    "#         print(\"DEBUGGING: in GCN: F.dropout: x.requires_grad = \",x.requires_grad)\n",
    "#         print(\"F.dropout(x, p=0.5, training=self.training) = \",x)\n",
    "        x = self.lin1(x) #why threee output layers thigns \n",
    "        x = self.lin2(x)\n",
    "        x = self.lin3(x)\n",
    "#         print(\"DEBUGGING: in GCN: self.lin*(x): x.requires_grad = \",x.requires_grad)\n",
    "#         print(\"self.lin3(x) = \",x)\n",
    "#         x = torch.sigmoid(x) #NOTE: DON'T SOFTMAX IF USING BCELOSS, USE SIGMOID INSTEAD\n",
    "#         print(\"torch.sigmoid(x) = \",x)\n",
    "#         print(\"DEBUGGING: in GCN: torch.sigmoid(x): x.requires_grad = \",x.requires_grad)\n",
    "        return x\n",
    "\n",
    "model = GCN(dataset.num_node_features,64,2)\n",
    "# model = GIN(in_channels=dataset.num_node_features,out_channels=2)\n",
    "#print(model)\n",
    "#print(\"\\ndataset[0].pos = \",dataset[0].pos)\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') \n",
    "devicee = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu') \n",
    "print(\"Device = \",device)\n",
    "model = model.to(device)\n",
    "print(\"DEBUGGING: torch.cuda.is_available() = \",torch.cuda.is_available())\n",
    "\n",
    "from torch.utils.data import random_split #TODO: SEE IF YOU CAN USE THIS\n",
    "# torch.manual_seed(12345)\n",
    "# print('DEBUGGING: BEFORE: dataset.y.shape = ',dataset.y.shape)\n",
    "dataset = dataset.shuffle() #shuffle (randmoize placement of it) not sure if this is needed. \n",
    "#print('DEBUGGING: AFTER:  dataset.y.shape = ',dataset.y.shape)\n",
    "\n",
    "#print(len(dataset)) \n",
    "\n",
    "fracs = [0.8, 0.1, 0.1] #percent of dataset used for training testing and validatoin 80%,10%,10% #NOTE: SHOULD CHECK np.sum(fracs) == 1 and len(fracs)==3\n",
    "fracs = [torch.sum(torch.tensor(fracs[:idx])) for idx in range(1,len(fracs)+1)] #get the indexes for training ... parts to use. \n",
    "#print(fracs)\n",
    "split1, split2 = [int(len(dataset)*frac) for frac in fracs[:-1]] \n",
    "train_dataset = dataset[:split1]\n",
    "val_dataset = dataset[split1:split2]\n",
    "test_dataset = dataset[split2:] \n",
    "\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of validation graphs: {len(val_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}') \n",
    "\n",
    "from torch_geometric.loader import DataLoader \n",
    "#from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "batch_size = 18\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)#, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset,  batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False) \n",
    "\n",
    "model = GCN(dataset.num_node_features, dataset.num_classes, 2).to(device) #initiate the model, #2 is the number of outputs here is 2 as pion_z, proton_z \n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3) #get the optimizer\n",
    "\n",
    "data_labels = train_dataset.y \n",
    "#weight_signal = counts[1]/counts[0]#DEBUGGING MULTIPLY BY 2 ...\n",
    "#print(\"weight_signal = \",weight_signal) \n",
    "# weight = torch.FloatTensor([weight_signal, 1.0]).to(device) #NOTE: That labels are [sg?,bg?] so label 0 in this case is sg and label 1 is bg.\n",
    "losss = torch.nn.MSELoss(reduction = 'mean').to(device)\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train() #initailize the model\n",
    "    #for i, data in tqdm(enumerate(train_loader)): #perhaps tqdm(enumerate(train_loader)), i is index, data jsut moves through all the dtaa in trainingg\n",
    "    for i,data in enumerate(train_loader):\n",
    "        data = data.to(device) #switch to GPU \n",
    "        optimizer.zero_grad() #\n",
    "        out = model(data.x, data.edge_index, data.batch).to(device)  # Perform a single forward pass\n",
    "        yy = []\n",
    "        for j in range(0,2*len(out),2): \n",
    "            fuckk = data.y[j]; fuckj = data.y[j+1]\n",
    "            yy +=[[fuckk.item(),fuckj.item()]]\n",
    "        yy = torch.tensor(yy).to(device)\n",
    "        loss = losss(out, yy).to(device) #compute the loss\n",
    "        loss.backward() #get the gradients. \n",
    "        optimizer.step() #take a step. \n",
    "        \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score \n",
    "\n",
    "def test(loader):\n",
    "    length = len(loader.dataset)\n",
    "    model.eval() #evaluate teh model.\n",
    "    \n",
    "    #mse_tot = []\n",
    "    mse_total = 0\n",
    "    mse_pi = 0\n",
    "    mse_p = 0\n",
    "    #r\n",
    "    #for data in tqdm(loader):  # Iterate in batches over the training/test dataset.\n",
    "    for data in loader:\n",
    "        data = data.to(device) #put to GPU \n",
    "        out = model(data.x, data.edge_index, data.batch).to(device) #evalueate \n",
    "        #this and the for loop is converting data.y to a tensor in the same shape as out rows and 2 columns first is y_pion second is y_proton\n",
    "        yy = []\n",
    "        for j in range(0,2*len(out),2): \n",
    "            yy +=[[data.y[j].item(),data.y[j+1].item()]]\n",
    "        yy = torch.tensor(yy).to(device)\n",
    "        loss = losss(out, yy).cpu() #getting teh loss function\n",
    "        mse_total+=loss.item() #getting the mse (total) \n",
    "        for j in range(len(out)): \n",
    "            #x_pi = out[j][0]; x_p =out[j][1]\n",
    "            \n",
    "            mse_pi += (out[j][0].item()-yy[j][0].item() )**2\n",
    "            mse_p +=(out[j][1].item()-yy[j][1].item())**2\n",
    "            \n",
    "        #)\n",
    "    return mse_total/length, np.sqrt(mse_total/length), mse_pi/length, np.sqrt(mse_pi/length), mse_p/length, np.sqrt(mse_p/length)\n",
    "\n",
    "        \n",
    "        \n",
    "def print_out():\n",
    "    model.eval() #initailize the model\n",
    "    #for i, data in tqdm(enumerate(train_loader)): #perhaps tqdm(enumerate(train_loader)), i is index, data jsut moves through all the dtaa in trainingg\n",
    "    outt= []\n",
    "    for i,data in enumerate(train_loader):\n",
    "        data = data.to(devicee) #switch to GPU \n",
    "        optimizer.zero_grad() #\n",
    "        out = model(data.x, data.edge_index, data.batch).to(devicee)  # Perform a single forward pass\n",
    "        #yy = []\n",
    "        #for j in range(0,2*len(out),2):\n",
    "        #    fuckk = data.y[j]; fuckj = data.y[j+1]\n",
    "        #    yy +=[[fuckk.item(),fuckj.item()]]\n",
    "        #yy = torch.tensor(yy).to(device)\n",
    "        #loss = losss(out, yy).cpu() #compute the loss\n",
    "        outt+=[out.cpu()]\n",
    "    return outt \n",
    "\n",
    "\n",
    "# for name, param in model.named_parameters(): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-senegal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "working-group",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Caught IndexError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/w/hallb-scshelf2102/clas12/users/mencke/venv/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\", line 85, in _worker\n    output = module(*input, **kwargs)\n  File \"/w/hallb-scshelf2102/clas12/users/mencke/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/w/hallb-scshelf2102/clas12/users/mencke/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/w/hallb-scshelf2102/clas12/users/mencke/venv/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py\", line 241, in forward\n    edge_index, edge_weight = gcn_norm(  # yapf: disable\n  File \"/w/hallb-scshelf2102/clas12/users/mencke/venv/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py\", line 99, in gcn_norm\n    edge_index, edge_weight = add_remaining_self_loops(\n  File \"/w/hallb-scshelf2102/clas12/users/mencke/venv/lib/python3.8/site-packages/torch_geometric/utils/loop.py\", line 623, in add_remaining_self_loops\n    mask = edge_index[0] != edge_index[1]\nIndexError: index 1 is out of bounds for dimension 0 with size 1\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m vall_metrics \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m:[], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m\"\u001b[39m:[], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse_pi\u001b[39m\u001b[38;5;124m'\u001b[39m:[], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmse_pi\u001b[39m\u001b[38;5;124m'\u001b[39m:[], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse_p\u001b[39m\u001b[38;5;124m'\u001b[39m:[], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmse_p\u001b[39m\u001b[38;5;124m'\u001b[39m:[] }\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nepochs):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m#print(\"BEFORE TRAIN()\") \u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m#print(\"BEFORE TEST(TRAIN_LOADER)\")\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     train_mse, train_rmse, train_mse_pi, train_rmse_pi, train_mse_p, train_rmse_p \u001b[38;5;241m=\u001b[39m test(train_loader)\n",
      "Cell \u001b[0;32mIn[12], line 188\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    186\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;66;03m#switch to GPU \u001b[39;00m\n\u001b[1;32m    187\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad() \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Perform a single forward pass\u001b[39;00m\n\u001b[1;32m    189\u001b[0m yy \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(out),\u001b[38;5;241m2\u001b[39m): \n",
      "File \u001b[0;32m/w/hallb-scshelf2102/clas12/users/mencke/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/w/hallb-scshelf2102/clas12/users/mencke/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[12], line 101\u001b[0m, in \u001b[0;36mGCN.forward\u001b[0;34m(self, x, edge_index, batch)\u001b[0m\n\u001b[1;32m     97\u001b[0m         x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mrelu() \u001b[38;5;66;03m#activation\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m#         x = torch.nn.function.elu(x)\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m#         print(\"DEBUGGING: in GCN: x.relu(): x.requires_grad = \",x.requires_grad)\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m#         print(\"x.relu() = \",x)\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(x)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m#         print(\"DEBUGGING: in GCN: self.bn2(x): x.requires_grad = \",x.requires_grad)\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m#         print(\"self.conv2(x,edge_index) = \",x)\u001b[39;00m\n",
      "File \u001b[0;32m/w/hallb-scshelf2102/clas12/users/mencke/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/w/hallb-scshelf2102/clas12/users/mencke/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/w/hallb-scshelf2102/clas12/users/mencke/venv/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:185\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodule_kwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    184\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 185\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m/w/hallb-scshelf2102/clas12/users/mencke/venv/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:200\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, replicas: Sequence[T], inputs: Sequence[Any], kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Any]:\n\u001b[0;32m--> 200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/w/hallb-scshelf2102/clas12/users/mencke/venv/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py:110\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m    108\u001b[0m     output \u001b[38;5;241m=\u001b[39m results[i]\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ExceptionWrapper):\n\u001b[0;32m--> 110\u001b[0m         \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/w/hallb-scshelf2102/clas12/users/mencke/venv/lib/python3.8/site-packages/torch/_utils.py:694\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 694\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mIndexError\u001b[0m: Caught IndexError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/w/hallb-scshelf2102/clas12/users/mencke/venv/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\", line 85, in _worker\n    output = module(*input, **kwargs)\n  File \"/w/hallb-scshelf2102/clas12/users/mencke/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/w/hallb-scshelf2102/clas12/users/mencke/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/w/hallb-scshelf2102/clas12/users/mencke/venv/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py\", line 241, in forward\n    edge_index, edge_weight = gcn_norm(  # yapf: disable\n  File \"/w/hallb-scshelf2102/clas12/users/mencke/venv/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py\", line 99, in gcn_norm\n    edge_index, edge_weight = add_remaining_self_loops(\n  File \"/w/hallb-scshelf2102/clas12/users/mencke/venv/lib/python3.8/site-packages/torch_geometric/utils/loop.py\", line 623, in add_remaining_self_loops\n    mask = edge_index[0] != edge_index[1]\nIndexError: index 1 is out of bounds for dimension 0 with size 1\n"
     ]
    }
   ],
   "source": [
    "nepochs =  2\n",
    "train_metrics = {'mse':[], \"rmse\":[], 'mse_pi':[], 'rmse_pi':[], 'mse_p':[], 'rmse_p':[] }\n",
    "vall_metrics = {'mse':[], \"rmse\":[], 'mse_pi':[], 'rmse_pi':[], 'mse_p':[], 'rmse_p':[] }\n",
    "\n",
    "for epoch in range(nepochs):\n",
    "    #print(\"BEFORE TRAIN()\") \n",
    "    train()\n",
    "    #print(\"BEFORE TEST(TRAIN_LOADER)\")\n",
    "    train_mse, train_rmse, train_mse_pi, train_rmse_pi, train_mse_p, train_rmse_p = test(train_loader)\n",
    "    \n",
    "    train_metrics['mse'].append(train_mse)\n",
    "    train_metrics['rmse'].append(train_rmse)\n",
    "    train_metrics['mse_pi'].append(train_mse_pi)\n",
    "    train_metrics['rmse_pi'].append(train_rmse_pi) \n",
    "    train_metrics['mse_p'].append(train_mse_p)\n",
    "    train_metrics['rmse_p'].append(train_rmse_p)\n",
    "    \n",
    "    #print(\"BEFORE TEST(VAL_LOADER)\")\n",
    "    vall_mse, vall_rmse, vall_mse_pi, vall_rmse_pi, vall_mse_p, vall_rmse_p = test(val_loader) \n",
    "    #if epoch==0 or val_roc_auc >np.max(val_metrics[\"roc_auc\"]) :\n",
    "    #    model_best_auc = model\n",
    "    #    PATH = '/work/clas12/users/mfmce/CLAS12_Lambda_resolution_REU_2023/model_best_auc.pt'\n",
    "    #    torch.save({\n",
    "    #        'epoch': epoch,\n",
    "    #        'model_state_dict': model.state_dict(),\n",
    "    #        'optimizer_state_dict': optimizer.state_dict(),\n",
    " #             'loss': loss,\n",
    "    #        }, PATH) \n",
    "    \n",
    "    vall_metrics['mse'].append(vall_mse)\n",
    "    vall_metrics['rmse'].append(vall_rmse)\n",
    "    vall_metrics['mse_pi'].append(vall_mse)\n",
    "    vall_metrics['rmse_pi'].append(vall_mse)\n",
    "    vall_metrics['mse_p'].append(vall_mse)\n",
    "    vall_metrics['rmse_p'].append(vall_mse)  \n",
    "    if epoch==0:\n",
    "        print(\"Epoch \",epoch,\" Train mse: \",train_mse,\" Train rmse: \",train_rmse,\" Train mse pion: \",train_mse_pi,\n",
    "              \" Train rmse pion: \",train_rmse_pi, \"Train mse proton:\",train_mse_p, \"Train rmse proton:\",train_rmse_p)\n",
    "        print(\"Epoch \",epoch,\" Validation mse: \",vall_mse,\" Validation rmse: \",vall_rmse,\" Validation mse pion: \",vall_mse_pi,\n",
    "              \" Validation rmse pion: \",vall_rmse_pi, \"Validation mse proton:\",vall_mse_p, \"Validation rmse proton:\", vall_rmse_p) \n",
    "    if epoch%9==0: \n",
    "        print(\"Epoch \",epoch,\" Train mse: \",train_mse,\" Train rmse: \",train_rmse,\" Train mse pion: \",train_mse_pi,\n",
    "              \" Train rmse pion: \",train_rmse_pi, \"Train mse proton:\",train_mse_p, \"Train rmse proton:\",train_rmse_p)\n",
    "        print(\"Epoch \",epoch,\" Validation mse: \",vall_mse,\" Validation rmse: \",vall_rmse,\" Validation mse pion: \",vall_mse_pi,\n",
    "              \" Validation rmse pion: \",vall_rmse_pi, \"Validation mse proton:\",vall_mse_p, \"Validation rmse proton:\", vall_rmse_p) \n",
    "    if epoch==1:\n",
    "        #a = print_out() \n",
    "        print(\"Epoch \",epoch,\" Train mse: \",train_mse,\" Train rmse: \",train_rmse,\" Train mse pion: \",train_mse_pi,\n",
    "              \" Train rmse pion: \",train_rmse_pi, \"Train mse proton:\",train_mse_p, \"Train rmse proton:\",train_rmse_p)\n",
    "        print(\"Epoch \",epoch,\" Validation mse: \",vall_mse,\" Validation rmse: \",vall_rmse,\" Validation mse pion: \",vall_mse_pi,\n",
    "              \" Validation rmse pion: \",vall_rmse_pi, \"Validation mse proton:\",vall_mse_p, \"Validation rmse proton:\", vall_rmse_p) \n",
    "model.eval() #initailize the model\n",
    "    #for i, data in tqdm(enumerate(train_loader)): #perhaps tqdm(enumerate(train_loader)), i is index, data jsut moves through all the dtaa in trainingg\n",
    "outt= []\n",
    "for i,data in enumerate(train_loader):\n",
    "    data = data.to(devicee) #switch to GPU \n",
    "    optimizer.zero_grad() #\n",
    "    out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass\n",
    "    #yy = []\n",
    "    #for j in range(0,2*len(out),2):\n",
    "    #    fuckk = data.y[j]; fuckj = data.y[j+1]\n",
    "    #    yy +=[[fuckk.item(),fuckj.item()]]\n",
    "    #yy = torch.tensor(yy).to(device)\n",
    "    #loss = losss(out, yy).cpu() #compute the loss\n",
    "    outt+=[out]\n",
    "#return outt  0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-millennium",
   "metadata": {},
   "outputs": [],
   "source": [
    "/work/clas12/users/mencke/venv/slurmm.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-discharge",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-stretch",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = [i for i in range(len(train_metrics[\"mse\"]))] \n",
    "plt.figure()\n",
    "plt.title('Training epoch vs. MSE') \n",
    "plt.plot(epochs, train_metrics['mse'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('MSE')\n",
    "\n",
    "\n",
    "plt.title('Validation epoch vs. MSE') \n",
    "plt.plot(epochs, vall_metrics['mse'])\n",
    "plt.xlabel('epoch') \n",
    "plt.ylabel('MSE')\n",
    "print(train_metrics['mse'])\n",
    "print(vall_metrics['mse']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-anatomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbatch submit.sh >> ouiyfgh.txt \n",
    "seff 23308894 (job number)\n",
    "\n",
    "Apptainer> squeue -u mencke\n",
    "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
    "          23305374   jupyter jupyterh   mencke  R    2:26:05      1 sciml2102\n",
    "Apptainer> ls /farm_out/mencke\n",
    "clas12Lambdastuff-23308800-sciml2401.err    jupyterhub-spawner-22293434-farm1942.log    jupyterhub-spawner-22758730-farm180246.log  jupyterhub-spawner-23274871-sciml2101.log\n",
    "clas12Lambdastuff-23308800-sciml2401.out    jupyterhub-spawner-22456262-farm180247.log  jupyterhub-spawner-22877740-sciml2101.log   jupyterhub-spawner-23305374-sciml2102.log\n",
    "jupyterhub-spawner-21998791-farm180246.log  jupyterhub-spawner-22559614-sciml2102.log   jupyterhub-spawner-23013279-farm180246.log\n",
    "jupyterhub-spawner-22222528-farm2325.log    jupyterhub-spawner-22668376-farm180246.log  jupyterhub-spawner-23128719-sciml2402.log\n",
    "Apptainer> clas12Lambdastuff-23308800-sciml2401.out\n",
    "bash: clas12Lambdastuff-23308800-sciml2401.out: command not found\n",
    "Apptainer> emacs clas12Lambdastuff-23308800-sciml2401.out\n",
    "Apptainer> emacs /farm_out/mencke/clas12Lambdastuff-23308800-sciml2401.out\n",
    "Apptainer> emacs /farm_out/mencke/clas12Lambdastuff-23308800-sciml2401.err\n",
    "Apptainer> echo idk >> testtttt_file.txt\n",
    "Apptainer> cat testtttt_file.txt \n",
    "idk\n",
    "Apptainer> sbatch submit.sh >> ouiyfgh.txt\n",
    "Apptainer> cat ouiyfgh.txt \n",
    "Submitted batch job 23308894\n",
    "Apptainer> seff 23308894\n",
    "Job ID: 23308894\n",
    "Cluster: scicomp\n",
    "User/Group: mencke/root\n",
    "State: COMPLETED (exit code 0)\n",
    "Cores: 1\n",
    "CPU Utilized: 00:00:00\n",
    "CPU Efficiency: 0.00% of 00:00:03 core-walltime\n",
    "Job Wall-clock time: 00:00:03\n",
    "Memory Utilized: 1.38 MB\n",
    "Memory Efficiency: 0.03% of 3.91 GB\n",
    "Apptainer> emacs submit.sh\n",
    "Apptainer> emacs job.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-smell",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-handling",
   "metadata": {},
   "outputs": [],
   "source": [
    "#another examplee\n",
    "\n",
    "Apptainer> cd /work/clas12/users/mencke\n",
    "Apptainer> ls\n",
    "dir_name_2    job.sh   ouiyfgh.txt                   pyg_test_rec_traj_dataset_111  pyg_test_rec_traj_dataset_5_28_24  pyg_test_rec_traj_dataset_69_99  submit.sh   testtttt_file.txt\n",
    "iiiiiiii.txt  job.sh~  pyg_test_rec_traj_dataset_11  pyg_test_rec_traj_dataset_22   pyg_test_rec_traj_dataset_69_9     pyg_test_rec_traj_dataset_69_9p  submit.sh~  venv\n",
    "Apptainer> /dir_name_2\n",
    "bash: /dir_name_2: No such file or directory\n",
    "Apptainer> cd /work/clas12/users/mencke/dir_name_2\n",
    "Apptainer> ls\n",
    "testt_one  testt.py\n",
    "Apptainer> cd /work/clas12/users/mencke/dir_name_2\n",
    "Apptainer> cd /work/clas12/users/mencke/dir_name_2\n",
    "Apptainer> ls\n",
    "testt_one  testt_one.py  testt.py\n",
    "Apptainer> emacs submit.sh\n",
    "Apptainer> cd /work/clas12/users/mencke\n",
    "Apptainer> cd /work/clas12/users/mencke\n",
    "Apptainer> emacs submit.sh\n",
    "Apptainer> emacs job.sh\n",
    "Apptainer> emacs job.sh\n",
    "Apptainer> sbatch submit.sh\n",
    "Submitted batch job 23321341"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-loading",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choice-wilderness",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy\n",
    "uproot\n",
    "10:14\n",
    "awkward\n",
    "10:15\n",
    "pandas\n",
    "matplotlib\n",
    "10:15\n",
    "hipopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-thousand",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-newport",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
