{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "stainless-clinic",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"\"\"print('testing_1')\n",
    "#import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "#import numpy.ma as ma \n",
    "#import awkward as ak\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch_geometric as tg\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "#import torch\n",
    "from torch_geometric.data import InMemoryDataset, download_url\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "#NOTE: NEW 2/20/23 \n",
    "from typing import List, Union\n",
    "\n",
    "from torch_geometric.data import Data, HeteroData\n",
    "from torch_geometric.data.datapipes import functional_transform\n",
    "from torch_geometric.transforms import BaseTransform \n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "root = '/work/clas12/users/mencke/pyg_test_rec_traj_dataset_111'\n",
    "class MyOwnDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.load(self.processed_paths[0])\n",
    "        # For PyG<2.4:\n",
    "        # self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['some_file_1', 'some_file_2']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "\n",
    "    def process(self):\n",
    "        # Read data into huge `Data` list.\n",
    "        data_list = None\n",
    "\n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(data) for data in data_list]\n",
    "\n",
    "        self.save(data_list, self.processed_paths[0])\n",
    "        # For PyG<2.4:\n",
    "        # torch.save(self.collate(data_list), self.processed_paths[0])\n",
    "\n",
    "# Create PyG Dataset\n",
    "#root = '/work/clas12/users/mfmce/pyg_test_rec_traj_dataset_5_28_24/' # 3_14_24 #OLD\n",
    "dataset = MyOwnDataset(\n",
    "            root,\n",
    "            transform=None, #T.Compose([T.ToUndirected(),T.KNNGraph(k=6)]),\n",
    "            pre_transform=None,\n",
    "            pre_filter=None\n",
    "        )\n",
    "dataset\n",
    "\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import GraphConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.nn.norm import GraphNorm, BatchNorm \n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GCN, self).__init__()\n",
    "#         torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)#.jittable() #NOTE: NEEDED FOR DEPLOYMENT IN CMAKE\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)#.jittable()\n",
    "        #self.block2 = nn.DataParallel(self.block2)\n",
    "        #self.conv2 = torch.nn.DataParallel(self.conv2) #this was trying the parallization thing. \n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)#.jittable()\n",
    "        #self.conv3 = torch.nn.DataParallel(self.conv3)\n",
    "        self.lin1 = Linear(hidden_channels, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, hidden_channels)\n",
    "        self.lin3 = Linear(hidden_channels, out_channels)\n",
    "        self.bn1 = torch_geometric.nn.norm.GraphNorm(hidden_channels)\n",
    "        self.bn2 = torch_geometric.nn.norm.GraphNorm(hidden_channels)\n",
    "        self.bn3 = torch_geometric.nn.norm.GraphNorm(hidden_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch): \n",
    "        # 1. Obtain node embeddings \n",
    "       # x = self.conv1(x, edge_index) #input layer\n",
    "      #  x = self.bn1(x) #normalize it\n",
    "     #   x = x.relu() #activation\n",
    "#         x = torch.nn.function.elu(x)\n",
    "#        x = self.conv2(x, edge_index)\n",
    "#        x = self.bn2(x)\n",
    "#        x = x.relu() \n",
    "#         print(\"x.relu() = \",x)\n",
    "#        x = self.conv3(x, edge_index)\n",
    "#        x = self.bn3(x)\n",
    "#         # 2. Readout layer\n",
    " #       x = global_mean_pool(x, batch) #what is this for.           # [batch_size, hidden_channels]\n",
    "  #      x = F.dropout(x, p=0.5, training=self.training) #for overfitting\n",
    "   #     x = self.lin3(x)\n",
    "        \n",
    "        x = self.conv1(x, edge_index) #input layer                             \n",
    "                                                      \n",
    "        x = self.bn1(x) #normalize it                                          \n",
    "\n",
    "        x = x.relu() #activation                                               \n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.bn2(x)\n",
    "        x = x.relu()\n",
    "#         print(\"x.relu() = \",x)                                               \n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = self.bn3(x)\n",
    "#         # 2. Readout layer                                                   \n",
    "        x = global_mean_pool(x, batch)\n",
    "        # 3. Apply a final classifier                                          \n",
    "        x = F.dropout(x, p=0.5, training=self.training) #for overfittin        \n",
    "        x = self.lin3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = GCN(dataset.num_node_features,64,2)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') \n",
    "#devicee = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu') \n",
    "print(\"Device = \",device)\n",
    "model = model.to(device)\n",
    "print(\"DEBUGGING: torch.cuda.is_available() = \",torch.cuda.is_available())\n",
    "\n",
    "from torch.utils.data import random_split #TODO: SEE IF YOU CAN USE THIS\n",
    "# torch.manual_seed(12345)\n",
    "# print('DEBUGGING: BEFORE: dataset.y.shape = ',dataset.y.shape)\n",
    "dataset = dataset.shuffle() #shuffle (randmoize placement of it) not sure if this is needed. \n",
    "#print('DEBUGGING: AFTER:  dataset.y.shape = ',dataset.y.shape)\n",
    "\n",
    "#print(len(dataset)) \n",
    "\n",
    "fracs = [0.8, 0.1, 0.1] #percent of dataset used for training testing and validatoin 80%,10%,10% #NOTE: SHOULD CHECK np.sum(fracs) == 1 and len(fracs)==3\n",
    "fracs = [torch.sum(torch.tensor(fracs[:idx])) for idx in range(1,len(fracs)+1)] #get the indexes for training ... parts to use. \n",
    "#print(fracs)\n",
    "split1, split2 = [int(len(dataset)*frac) for frac in fracs[:-1]] \n",
    "train_dataset = dataset[:split1]\n",
    "val_dataset = dataset[split1:split2]\n",
    "test_dataset = dataset[split2:] \n",
    "\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of validation graphs: {len(val_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}') \n",
    "\n",
    "from torch_geometric.loader import DataLoader \n",
    "#from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)#, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset,  batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False) \n",
    "\n",
    "model = GCN(dataset.num_node_features, dataset.num_classes, 2).to(device) #initiate the model, #2 is the number of outputs here is 2 as pion_z, proton_z \n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3) #get the optimizer\n",
    "\n",
    "data_labels = train_dataset.y \n",
    "#weight_signal = counts[1]/counts[0]#DEBUGGING MULTIPLY BY 2 ...\n",
    "#print(\"weight_signal = \",weight_signal) \n",
    "# weight = torch.FloatTensor([weight_signal, 1.0]).to(device) #NOTE: That labels are [sg?,bg?] so label 0 in this case is sg and label 1 is bg.\n",
    "losss = torch.nn.MSELoss(reduction = 'mean').to(device)\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train() #initailize the model                                                                                                                                                                                                       \n",
    "    #for i, data in tqdm(enumerate(train_loader)): #perhaps tqdm(enumerate(train_loader)), i is index, data jsut moves through all the dtaa in trainingg                                                                                      \n",
    "    for i,data in enumerate(train_loader):\n",
    "        data = data.to(device) #switch to GPU                                                                                                                                                                                                 \n",
    "        optimizer.zero_grad() #                                                                                                                                                                                                               \n",
    "        out = model(data.x, data.edge_index, data.batch).to(device)  # Perform a single forward pass                                                                                                                                          \n",
    "        yy = []\n",
    "        for j in range(0,2*len(out),2):\n",
    "\n",
    "            yy +=[[data.y[j].item(), data.y[j+1].item()]]\n",
    "\n",
    "        yy = torch.tensor(yy).to(device)\n",
    "        loss = losss(out, yy).to(device) #compute the loss                                                                                                                                                                                    \n",
    "        loss.backward() #get the gradients.                                                                                                                                                                                                   \n",
    "        optimizer.step() #take a step.                                                                                                                                                                                                        \n",
    "\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "#from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def test(loader):\n",
    "    length = len(loader.dataset)\n",
    "    model.eval() #evaluate teh model.                                                                                                                                                                                                         \n",
    "\n",
    "    #mse_tot = []                                                                                                                                                                                                                             \n",
    "    mse_total = 0\n",
    "    mse_pi = 0\n",
    "    mse_p = 0\n",
    "    #r                                                                                                                                                                                                                                        \n",
    "    #for data in tqdm(loader):  # Iterate in batches over the training/test dataset.                                                                                                                                                          \n",
    "    for data in loader:\n",
    "        data = data.to(device) #put to GPU                                                                                                                                                                                                    \n",
    "        out = model(data.x, data.edge_index, data.batch).to(device) #evalueate                                                                                                                                                                \n",
    "        #this and the for loop is converting data.y to a tensor in the same shape as out rows and 2 columns first is y_pion second is y_proton                                                                                                \n",
    "        yy = []\n",
    "        for j in range(0,2*len(out),2):\n",
    "            yy +=[[data.y[j].item(),data.y[j+1].item()]]\n",
    "        yy = torch.tensor(yy).to(device)\n",
    "        loss = losss(out, yy).cpu() #getting teh loss function                                                                                                                                                                                \n",
    "        mse_total+=loss.item() #getting the mse (total)                                                                                                                                                                                       \n",
    "        for j in range(len(out)):\n",
    "            #x_pi = out[j][0]; x_p =out[j][1]                                                                                                                                                                                                 \n",
    "\n",
    "            mse_pi += (out[j][0].item()-yy[j][0].item() )**2\n",
    "            mse_p +=(out[j][1].item()-yy[j][1].item())**2\n",
    "\n",
    "        #)                                                                                                                                                                                                                                    \n",
    "    return mse_total/length, np.sqrt(mse_total/length), mse_pi/length, np.sqrt(mse_pi/length), mse_p/length, np.sqrt(mse_p/length)\n",
    "\n",
    "        \n",
    "def print_out():\n",
    "    model.eval() #initailize the model                                                                                                                                                                                                        \n",
    "    #for i, data in tqdm(enumerate(train_loader)): #perhaps tqdm(enumerate(train_loader)), i is index, data jsut moves through all the dtaa in trainingg                                                                                      \n",
    "    outt= []\n",
    "    for i,data in enumerate(train_loader):\n",
    "        data = data.to(device) #switch to GPU                                                                                                                                                                                                 \n",
    "        optimizer.zero_grad() #                                                                                                                                                                                                               \n",
    "        out = model(data.x, data.edge_index, data.batch).to(device)  # Perform a single forward pass                                                                                                                                          \n",
    "        out = out.cpu()\n",
    "        #yy = []                                                                                                                                                                                                                              \n",
    "        #for j in range(0,2*len(out),2):                                                                                                                                                                                                      \n",
    "        #    fuckk = data.y[j]; fuckj = data.y[j+1]                                                                                                                                                                                           \n",
    "        #    yy +=[[fuckk.item(),fuckj.item()]]                                                                                                                                                                                               \n",
    "        #yy = torch.tensor(yy).to(device)                                                                                                                                                                                                     \n",
    "        #loss = losss(out, yy).cpu() #compute the loss                                                                                                                                                                                        \n",
    "        outt+=[[out.detach().numpy()]]\n",
    "    return outt\n",
    "\n",
    "\n",
    "# for name, param in model.named_parameters():                                                                                                                                                                                                \n",
    "nepochs =  18\n",
    "train_metrics = {'mse':[], \"rmse\":[], 'mse_pi':[], 'rmse_pi':[], 'mse_p':[], 'rmse_p':[] }\n",
    "vall_metrics = {'mse':[], \"rmse\":[], 'mse_pi':[], 'rmse_pi':[], 'mse_p':[], 'rmse_p':[] }\n",
    "\n",
    "for epoch in range(nepochs):\n",
    "    if epoch ==(nepochs-1):\n",
    "        model.eval()\n",
    "        outt = []\n",
    "        for i, data in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            out = model(data.x, data.edge_index, data.batch).to(device)\n",
    "            out = out.cpu()\n",
    "            outt+=[[out.detach().numpy()]]\n",
    "        print(outt)\n",
    "        break\n",
    "    #print(\"BEFORE TRAIN()\")                                                                                                                                                                                                                  \n",
    "    train()\n",
    "    #print(\"BEFORE TEST(TRAIN_LOADER)\")                                                                                                                                                                                                       \n",
    "    train_mse, train_rmse, train_mse_pi, train_rmse_pi, train_mse_p, train_rmse_p = test(train_loader)\n",
    "\n",
    "    train_metrics['mse'].append(train_mse)\n",
    "    train_metrics['rmse'].append(train_rmse)\n",
    "    train_metrics['mse_pi'].append(train_mse_pi)\n",
    "    train_metrics['rmse_pi'].append(train_rmse_pi)\n",
    "    train_metrics['mse_p'].append(train_mse_p)\n",
    "    train_metrics['rmse_p'].append(train_rmse_p)\n",
    "\n",
    "    #print(\"BEFORE TEST(VAL_LOADER)\")                                                                                                                                                                                                         \n",
    "    vall_mse, vall_rmse, vall_mse_pi, vall_rmse_pi, vall_mse_p, vall_rmse_p = test(val_loader)\n",
    "    #if epoch==0 or val_roc_auc >np.max(val_metrics[\"roc_auc\"]) :                                                                                                                                                                             \n",
    "    #    model_best_auc = model                                                                                                                                                                                                               \n",
    "    #    PATH = '/work/clas12/users/mfmce/CLAS12_Lambda_resolution_REU_2023/model_best_auc.pt'                                                                                                                                                \n",
    "    #    torch.save({                                                                                                                                                                                                                         \n",
    "    #        'epoch': epoch,                                                                                                                                                                                                                  \n",
    "    #        'model_state_dict': model.state_dict(),                                                                                                                                                                                          \n",
    "    #        'optimizer_state_dict': optimizer.state_dict(),                                                                                                                                                                                  \n",
    " #             'loss': loss,                                                                                                                                                                                                                  \n",
    "    #        }, PATH)                                                                                                                                                                                                                         \n",
    "\n",
    "    vall_metrics['mse'].append(vall_mse)\n",
    "    vall_metrics['rmse'].append(vall_rmse)\n",
    "    vall_metrics['mse_pi'].append(vall_mse)\n",
    "    vall_metrics['rmse_pi'].append(vall_mse)\n",
    "    vall_metrics['mse_p'].append(vall_mse)\n",
    "    vall_metrics['rmse_p'].append(vall_mse)\n",
    "    if epoch%9==0:\n",
    "        print(\"Epoch \",epoch,\" Train mse: \",train_mse,\" Train rmse: \",train_rmse,\" Train mse pion: \",train_mse_pi,\n",
    "              \" Train rmse pion: \",train_rmse_pi, \"Train mse proton:\",train_mse_p, \"Train rmse proton:\",train_rmse_p)\n",
    "        print(\"Epoch \",epoch,\" Validation mse: \",vall_mse,\" Validation rmse: \",vall_rmse,\" Validation mse pion: \",vall_mse_pi,\n",
    "              \" Validation rmse pion: \",vall_rmse_pi, \"Validation mse proton:\",vall_mse_p, \"Validation rmse proton:\", vall_rmse_p)\n",
    "    if epoch==(nepochs-1):\n",
    "        a = print_out()\n",
    "        print(\"Epoch \",epoch,\" Train mse: \",train_mse,\" Train rmse: \",train_rmse,\" Train mse pion: \",train_mse_pi,\n",
    "              \" Train rmse pion: \",train_rmse_pi, \"Train mse proton:\",train_mse_p, \"Train rmse proton:\",train_rmse_p)\n",
    "        print(\"Epoch \",epoch,\" Validation mse: \",vall_mse,\" Validation rmse: \",vall_rmse,\" Validation mse pion: \",vall_mse_pi,\n",
    "              \" Validation rmse pion: \",vall_rmse_pi, \"Validation mse proton:\",vall_mse_p, \"Validation rmse proton:\", vall_rmse_p) \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = [i for i in range(len(train_metrics[\"mse\"]))] \n",
    "plt.figure()\n",
    "plt.title('Training epoch vs. MSE') \n",
    "plt.plot(epochs, train_metrics['mse'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('MSE')\n",
    "\n",
    "\n",
    "plt.title('Validation epoch vs. MSE') \n",
    "plt.plot(epochs, vall_metrics['mse'])\n",
    "plt.xlabel('epoch') \n",
    "plt.ylabel('MSE')\n",
    "\"\"\"\n",
    "\n",
    "f = open(\"/work/clas12/users/mencke/dir_name_2/testt_one.py\", \"w\")\n",
    "f.write(code) \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preliminary-liability",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = [i for i in range(len(train_metrics[\"mse\"]))] \n",
    "plt.figure()\n",
    "plt.title('Training epoch vs. MSE') \n",
    "plt.plot(epochs, train_metrics['mse'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('MSE')\n",
    "\n",
    "\n",
    "plt.title('Validation epoch vs. MSE') \n",
    "plt.plot(epochs, vall_metrics['mse'])\n",
    "plt.xlabel('epoch') \n",
    "plt.ylabel('MSE')\n",
    "print(train_metrics['mse'])\n",
    "print(vall_metrics['mse'])\n",
    "model.eval() #initailize the model\n",
    "    #for i, data in tqdm(enumerate(train_loader)): #perhaps tqdm(enumerate(train_loader)), i is index, data jsut moves through all the dtaa in trainingg\n",
    "outt= []\n",
    "for i,data in enumerate(train_loader):\n",
    "    data = data.to(devicee) #switch to GPU \n",
    "    optimizer.zero_grad() #\n",
    "    out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass\n",
    "    #yy = []\n",
    "    #for j in range(0,2*len(out),2):\n",
    "    #    fuckk = data.y[j]; fuckj = data.y[j+1]\n",
    "    #    yy +=[[fuckk.item(),fuckj.item()]]\n",
    "    #yy = torch.tensor(yy).to(device)\n",
    "    #loss = losss(out, yy).cpu() #compute the loss\n",
    "    outt+=[out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-eating",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
